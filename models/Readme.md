## models folder structure

This folder has been heavily modified to reconstruct the training stript as well as individual file inferencing. Here is the list of files and what they do:

-   ../dataset (put all dataset lmdb files here, download from [Kaggle](https://www.kaggle.com/datasets/dinmkeljiame/doctamper/data))<br>
    &emsp;&emsp;- DocTamperV1-SCD (test set)<br>
    &emsp;&emsp;- DocTamperV1-FCD (test set)<br>
    &emsp;&emsp;- DocTamperV1-TestingSet (test set)<br>
    &emsp;&emsp;- DocTamperV1-TrainingSet (training/eval set)<br>

-   losses/ (contains all custom loss functions. Original)
-   ouputs/ (contains saved model checkopints and logs. Generated by train_dtd)
-   tsroie/ (T-SROIE dataset handlers. Original, unused)
-   weights/ (contains model weights, download from [Baidu Drive](https://pan.baidu.com/s/166A9pentu3mwewY-79qHKg?pwd=vmhb) or [Google Drive](https://drive.google.com/drive/folders/11Ep8PJIrlIveudQaRulDOBENHGqw762a?usp=sharing), new)<br>
    &emsp;&emsp;- dtd_doctamper.pth (main DocTamper model weights, trained on/for DocTamper dataset, required)<br>
    &emsp;&emsp;- dtd_tsroie.pth (T-SROIE DocTamper model weights, trained for T-SROIE dataset, unused)<br>
    &emsp;&emsp;- swin_imagenet.pt (SWIN weights, optional. See changes made below)<br>
    &emsp;&emsp;- vph_imagenet.pt (VPH weights, optional. See changes made below)<br>
-   dtd.py (main DocTamper model py, uses fph, vph, swin, modified)
-   eval_dtd.py (script to eval DTD model, modified)
-   train_dtd.py (script to train DTD model, new)
-   predict.py (script to use DTD model to predict on an image, new)
-   log.py (script to setup logging, original)
-   metric.py (contains IOU metric handler, original)
-   swins.py (contains SWIN transformer code, original)
-   tamper_dataset.py (DataLoader for DTD model, reads lmdb dataset, modified)
-   test.jpg (an image for you to test predict)
-   utils.py (helper functions, original)

## changes made

This repo originally does not contain training code. The models dtd, vph, swin, are somewhat broken.
By broken I mean the author simply used

```python
self.vph = torch.load('weights/vph_imagenet.pt')
self.swin = torch.load('weights/swin_imagenet.pt')
```

which loads the vph and swin model weights and structure.
But actually the code for VPH and SWIN in the original repo implements different versions of VPH and SWIN so were not compatible with DTD or these weights.
the original repo is able to do eval because once loaded with above lines, DTD will discard the incompatible VPH and SWIN, and just use the model structure in pt files.
The author did also do `model.load_state_dict(checkpoint_pth_file)` later which may override the VPH and SWIN weights again.

These issues have been fixed. VPH and SWIN now adhere to the pt model structure above and are compatible with DTD.
The model will now work even if we don't import the pt files above.

Additionally, training code have been reconstructed from paper and clues in original code.
Single file inferencing code is written by Wenzhe and included as well.

## notes

-   the model predicts binary mask but is a segmented model. meaning it predicts the likelihood of both no-mask and yes-mask.
    -   e.g. for each pixel instead of 1 likelihood decimal between 0 to 1, it predicts 2 decimals.
    -   e.g. instead of [0.66], it may predict [2., 4.], notice the ratio is porportional to 0.66
    -   this may bring flexibility and accuracy for the model, at the cost of more VRAM requirement
    -   in training we will use cross entropy to compress the segmented prediction back to range of 0 to 1.
    -   in inferencing we just need to do argmax to collapse them into a binary mask of 0 or 1
-   only the blocks of swin transformer model is used.
    -   forward method is not used. Instead, DTD imports swin.layers and calls the layers directly
-   swin layers/blocks are dynamically created when you initialize it with params such as num_heads or depths
    -   DTD in paper used depths=[2,18,2]
-   DTD consumes quite a lot of VRAM when training. A 8G VRAM GPU can maybe train with workers=1 and batch_size=8.
    -   Beyond this the code will still work but training time significantly increases as it needs pagefile/swap IO
    -   batch size of 8 is a bit too small. This may cause model instability in training

## Below is original readme

#### The weights of the DTD for DocTamper and T-SROIE are now avaliable at [Baidu Drive](https://pan.baidu.com/s/166A9pentu3mwewY-79qHKg?pwd=vmhb) or [Google Drive](https://drive.google.com/drive/folders/11Ep8PJIrlIveudQaRulDOBENHGqw762a?usp=sharing) <Br/>

#### An Example [Colab Note Book](https://colab.research.google.com/drive/1rWaSKy2Rsy5welyvj6FbzF01o2zv8ips?usp=sharing) <Br/>

#### An example of dirs structure: <Br/>

---DocTamper/ <Br/>
&emsp;| <Br/>
&emsp;---qt_table.pk <Br/>
&emsp;---fph.py <Br/>
&emsp;---dtd.py <Br/>
&emsp;---swins.py <Br/>
&emsp;---eval_dtd.py <Br/>
&emsp;---pths/ <Br/>
&emsp;&emsp;| <Br/>
&emsp;&emsp;---dtd.pth <Br/>
&emsp;&emsp;---swin_imagenet.pt <Br/>
&emsp;&emsp;---vph_imagenet.pt <Br/>
&emsp;---DocTamperV1-FCD/ <Br/>
&emsp;&emsp;| <Br/>
&emsp;&emsp; ---data.mdb <Br/>
&emsp;&emsp; ---lock.mdb <Br/>
&emsp;---DocTamperV1-SCD/ <Br/>
&emsp;---DocTamperV1-TestingSet/ <Br/>
&emsp;---pks/ <Br/>

#### An example command to reproduce the results: <Br/>

<code>!CUDA_VISIBLE_DEVICES=0 python eval_dtd.py --lmdb_name DocTamperV1-FCD --pth pths/dtd_doctamper.pth --minq 75</code> <Br/> <Br/> <Br/>
